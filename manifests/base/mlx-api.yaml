# Copyright 2021 IBM Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
apiVersion: v1
kind: Service
metadata:
  name: mlx-api
  namespace: kubeflow
  labels:
    service: mlx-api
    environment: dev
spec:
  type: NodePort
  ports:
  - name: mlx-api
    port: 80
    targetPort: 8080
  selector:
    service: mlx-api
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mlx-api-configmap
  namespace: kubeflow
data:
  # for kfp context.json
  # Note: currently these is only one user profile and mlx namespace.
  #       use the context which using 'mlx' namespace, to create kfp.KfpClient
  #       and send proper user headers to ml-pipeline api
  #       need to find a way to support multi user profile in the future
  kfp-context: |
    {
      "namespace": "mlx",
      "client_authentication_header_name": "kubeflow-userid",
      "client_authentication_header_value": "mlx@ibm.com"
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlx-api
  namespace: kubeflow
  labels:
    service: mlx-api
    environment: dev
spec:
  selector:
    matchLabels:
       service: mlx-api
       environment: dev
  replicas: 1
  template:
    metadata:
      labels:
        service: mlx-api
        environment: dev
        version: v0.1.25-related-assets
    spec:
      serviceAccountName: mlx-api
      containers:
      - name: mlx-api-server
        image: mlexchange/mlx-api:nightly-main
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        resources:
          limits:
            cpu: 250m
            memory: 256Mi
        volumeMounts:
        - name: context
          mountPath: "/root/.config/kfp"
          readOnly: true
        livenessProbe:
          httpGet:
            path: /apis/v1alpha1/health_check?check_database=true&check_object_store=true
            port: 8080
          initialDelaySeconds: 120
          timeoutSeconds: 10
          periodSeconds: 60
          failureThreshold: 3
      volumes:
      - name: context
        configMap:
          name: mlx-api-configmap
          items:
          - key: kfp-context
            path: context.json
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: mlx-api-access
subjects:
- kind: ServiceAccount
  name: mlx-api
  namespace: kubeflow
roleRef:
  kind: ClusterRole
  name: mlx-api-access
  apiGroup: rbac.authorization.k8s.io
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: mlx-api-access
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log", "secrets", "events", "serviceaccounts", "configmaps",
    "persistentvolumeclaims", "limitranges"]
  verbs: ["get", "list", "create", "update", "delete", "patch", "watch"]
- apiGroups: ["serving.kubeflow.org"]
  resources: ["inferenceservices"]
  verbs: ["get", "list", "create", "update", "delete", "patch", "watch"]
- apiGroups: ["serving.knative.dev"]
  resources: ["services", "revisions", "configurations"]
  verbs: ["get", "list", "create", "update", "delete", "patch", "watch"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mlx-api
  namespace: kubeflow
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: mlx-api
  namespace: kubeflow
spec:
  gateways:
  - kubeflow-gateway
  hosts:
  - '*'
  http:
  - match:
    - uri:
        prefix: /apis/v1alpha1
    rewrite:
      uri: /apis/v1alpha1
    route:
    - destination:
        host: mlx-api.kubeflow.svc.cluster.local
        port:
          number: 80
    timeout: 300s
